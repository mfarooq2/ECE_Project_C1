{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1abfd1c-f4df-4e61-bff2-01526bb7d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0eb015d-2d7b-499c-8eb7-8560a08a64aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 549761.88it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.07it/s]\n"
     ]
    }
   ],
   "source": [
    "def data_frame_adder(temp_frame,file_name):\n",
    "    file_name=file_name.split('.csv')[0]\n",
    "    temp_frame['file_name']=file_name\n",
    "    temp_frame['subject']=temp_frame['file_name'].apply(lambda x: int(x.split('subject_')[1].split('_')[0]))\n",
    "    temp_frame['session']=temp_frame['file_name'].apply(lambda x: int(x.split('subject_')[1].split('_')[1]))\n",
    "    #temp_frame['type']=temp_frame['file_name'].apply(lambda x: x.split('__')[1])\n",
    "    temp_frame = temp_frame.drop(columns=['file_name'])\n",
    "    temp_frame = temp_frame[temp_frame.columns[::-1]]\n",
    "    temp_frame = temp_frame.sort_values(by=['session','subject'], axis=0)\n",
    "    col_list1 = list(temp_frame.columns)[0:2]\n",
    "    col_list2 = list(temp_frame.columns)[2:]\n",
    "    col_list2.sort()\n",
    "    col_list=col_list1+col_list2\n",
    "    \n",
    "    #temp_frame = swap_columns(temp_frame, 'subject', 'session')\n",
    "    # Swapping the columns\n",
    "    temp_frame = temp_frame.reindex(columns=col_list)\n",
    "\n",
    "    return temp_frame\n",
    "Training_data_files=glob.glob('TrainingData/*.csv')\n",
    "file_name_list_x=[]\n",
    "file_name_list_x_time=[]\n",
    "file_name_list_y=[]\n",
    "file_name_list_y_time=[]\n",
    "for file_name in tqdm(Training_data_files):\n",
    "    if 'x.csv' in file_name:\n",
    "        file_name_list_x.append(file_name)\n",
    "    elif 'x_time.csv' in file_name:\n",
    "        file_name_list_x_time.append(file_name)\n",
    "    elif 'y.csv' in file_name:\n",
    "        file_name_list_y.append(file_name)\n",
    "    else:\n",
    "        file_name_list_y_time.append(file_name)\n",
    "file_name_list_x.sort()\n",
    "file_name_list_x_time.sort()\n",
    "file_name_list_y.sort()\n",
    "file_name_list_y_time.sort()\n",
    "Subject_list= [f.split('_')[1] for f in file_name_list_x]\n",
    "Session_list= [f.split('_')[2] for f in file_name_list_x]\n",
    "\n",
    "x_sensor_dat=pd.DataFrame([])\n",
    "y_sensor_dat=pd.DataFrame([])\n",
    "x_time_dat=[]\n",
    "for sub,sess in tqdm(zip(Subject_list,Session_list)):\n",
    "    #x_sensor_dat=pd.DataFrame(x_sensor_dat.append(pd.read_csv(f\"TrainingData/subject_{sub}_{sess}__x.csv\",header=None)))\n",
    "    \n",
    "    x_sensor_dat=pd.concat([pd.read_csv(f\"TrainingData/subject_{sub}_{sess}__x.csv\",header=None),pd.read_csv(f\"TrainingData/subject_{sub}_{sess}__x_time.csv\",header=None).rename(columns={0:'time_stamp'})],axis=1)\n",
    "    features_to_normalize = [0,1,2,3,4,5]\n",
    "\n",
    "    x_sensor_dat[features_to_normalize] = x_sensor_dat[features_to_normalize].apply(lambda x:(x-x.min())/(x.max()-x.min()))\n",
    "    x_sensor_dat['measurements']=x_sensor_dat.apply(lambda x: np.array([x[0],x[1],x[2],x[3],x[4],x[5]]),axis=1)\n",
    "    x_sensor_dat=x_sensor_dat[['time_stamp','measurements']]\n",
    "    break\n",
    "    #x_sensor_dat=x_sensor_dat.set_index('time_stamp').asfreq('0.025S')\n",
    "    x_sensor_dat['Subject']=int(sub)\n",
    "    x_sensor_dat['Session']=int(sess)\n",
    "    #x_sensor_dat=x_sensor_dat.set_index('time_stamp').asfreq('0.025S')\n",
    "    \n",
    "    y_sensor_dat=pd.concat([pd.read_csv(f\"TrainingData/subject_{sub}_{sess}__y.csv\",header=None),pd.read_csv(f\"TrainingData/subject_{sub}_{sess}__y_time.csv\",header=None).rename(columns={0:'time_stamp'})],axis=1).rename(columns={0:'labels'})\n",
    "    #y_sensor_dat['labels']=y_sensor_dat.apply(lambda y: [y[0],y[1],y[2],y[3]],axis=1)\n",
    "    y_sensor_dat=y_sensor_dat[['time_stamp','labels']]\n",
    "    #y_sensor_dat[\"time_stamp\"]=pd.to_datetime(y_sensor_dat[\"time_stamp\"],unit='s').round('ms')\n",
    "    trp=pd.concat(\n",
    "        [pd.DataFrame({'labels':0},index=[x_sensor_dat.index[-1]]),pd.DataFrame({'time_stamp':np.max(x_sensor_dat['time_stamp'])},index=[x_sensor_dat.index[-1]])\n",
    "                         ]\n",
    "         ,axis=1)\n",
    "    y_sensor_dat=pd.concat([y_sensor_dat,trp],axis=0)\n",
    "    trp=pd.concat([pd.DataFrame({'labels':0},index=[x_sensor_dat.index[0]]),pd.DataFrame({'time_stamp':np.min(x_sensor_dat['time_stamp'])},index=[x_sensor_dat.index[0]])],axis=1)\n",
    "    y_sensor_dat=pd.concat([trp,y_sensor_dat],axis=0)\n",
    "    # y_sensor_dat=y_sensor_dat.set_index('time_stamp').asfreq('0.025S')\n",
    "    #y_sensor_dat['Subject']=int(sub)\n",
    "    #y_sensor_dat['Session']=int(sess)\n",
    "    x_sensor_dat[\"time_stamp\"]=pd.to_datetime(x_sensor_dat[\"time_stamp\"],unit='s').round('ms')\n",
    "    x_sensor_dat=x_sensor_dat.set_index('time_stamp')\n",
    "    x_sensor_dat=x_sensor_dat.asfreq('0.025S')\n",
    "    \n",
    "    y_sensor_dat[\"time_stamp\"]=pd.to_datetime(y_sensor_dat[\"time_stamp\"],unit='s').round('ms')\n",
    "    y_sensor_dat=y_sensor_dat.set_index('time_stamp')\n",
    "    y_sensor_dat=y_sensor_dat.asfreq(freq='0.025S', method='bfill')\n",
    "    #y_sensor_dat=y_sensor_dat.set_index('time_stamp').time.asfreq(freq='0.025S', method='bfill')\n",
    "                                        #.resample('0.025S').interpolate(method='linear')\n",
    "    x_y_dat=pd.merge(x_sensor_dat,y_sensor_dat, how='inner', left_index=True, right_index=True)\n",
    "    x_y_dat.to_parquet(f\"pre_processed_training/subject_{sub}_session_{sess}.gzip\",compression='gzip')\n",
    "files=glob.glob('pre_processed_training/*.gzip')\n",
    "total_training_data=pd.DataFrame([])\n",
    "for f in tqdm(files):\n",
    "    total_training_data=pd.concat([total_training_data,pd.read_parquet(f, engine='auto')],axis=0)\n",
    "# total_training_data=total_training_data.sort_values(['Subject','Session','time_stamp'])\n",
    "# total_training_data=total_training_data.reset_index()\n",
    "# total_training_data['epoch'] = total_training_data['time_stamp'].sub(pd.Timestamp('1970-01-01 00:00:00.000'))\n",
    "# total_training_data['epoch']=total_training_data['epoch'].dt.total_seconds()\n",
    "# total_training_data=total_training_data[['Subject','Session','epoch','measurements','labels']]\n",
    "# total_training_data_grouped=total_training_data.groupby(['Subject','Session','epoch']).agg({'measurements':[np.mean],'labels':[np.mean]})\n",
    "# total_training_data_grouped.columns = total_training_data_grouped.columns.droplevel(1)\n",
    "# total_training_data_grouped=total_training_data_grouped.reset_index(level=['epoch'])\n",
    "# total_training_data_grouped.to_parquet(f\"combined_sampled/training.gzip\",compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4a6a75-77c8-4cd6-b402-c0a4356f13a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780630fc-b3fa-4ba8-bf72-94eb8287d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sensor_dat=pd.concat([pd.read_csv(f\"TrainingData/subject_{sub}_{sess}__x.csv\",header=None),pd.read_csv(f\"TrainingData/subject_{sub}_{sess}__x_time.csv\",header=None).rename(columns={0:'time_stamp'})],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f246e1-698c-4372-b467-0b1785a25225",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_normalize = [0,1,2,3,4,5]\n",
    "\n",
    "x_sensor_dat[features_to_normalize] = x_sensor_dat[features_to_normalize].apply(lambda x:(x-x.mean())/ x.std(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a22bd73-6bc0-4792-a491-409310c43d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>measurements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>[0.5537007437504876, 0.6039797511273846, 0.437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025</td>\n",
       "      <td>[0.5505298486491442, 0.6058937153454164, 0.436...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050</td>\n",
       "      <td>[0.5550970330543998, 0.6067218203554878, 0.436...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075</td>\n",
       "      <td>[0.5589869478192381, 0.6067599340291648, 0.436...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100</td>\n",
       "      <td>[0.5546444602507224, 0.6029812631632441, 0.435...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37885</th>\n",
       "      <td>947.125</td>\n",
       "      <td>[0.5216805699350552, 0.621890404679508, 0.4046...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37886</th>\n",
       "      <td>947.150</td>\n",
       "      <td>[0.5217144168192075, 0.621606132135399, 0.4035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37887</th>\n",
       "      <td>947.175</td>\n",
       "      <td>[0.5214098331646096, 0.621512015222769, 0.4034...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37888</th>\n",
       "      <td>947.200</td>\n",
       "      <td>[0.5213362407691913, 0.6217677702262688, 0.403...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37889</th>\n",
       "      <td>947.225</td>\n",
       "      <td>[0.5202265583515304, 0.6218893212451293, 0.404...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37890 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_stamp                                       measurements\n",
       "0           0.000  [0.5537007437504876, 0.6039797511273846, 0.437...\n",
       "1           0.025  [0.5505298486491442, 0.6058937153454164, 0.436...\n",
       "2           0.050  [0.5550970330543998, 0.6067218203554878, 0.436...\n",
       "3           0.075  [0.5589869478192381, 0.6067599340291648, 0.436...\n",
       "4           0.100  [0.5546444602507224, 0.6029812631632441, 0.435...\n",
       "...           ...                                                ...\n",
       "37885     947.125  [0.5216805699350552, 0.621890404679508, 0.4046...\n",
       "37886     947.150  [0.5217144168192075, 0.621606132135399, 0.4035...\n",
       "37887     947.175  [0.5214098331646096, 0.621512015222769, 0.4034...\n",
       "37888     947.200  [0.5213362407691913, 0.6217677702262688, 0.403...\n",
       "37889     947.225  [0.5202265583515304, 0.6218893212451293, 0.404...\n",
       "\n",
       "[37890 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sensor_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac6d1080-7ee9-4274-9e0d-2e0d09bffa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0.55370074, 0.60397975, 0.43772388, 0.4631038 , 0.46439293,\n",
       "              0.41251359])                                               ,\n",
       "       array([0.55052985, 0.60589372, 0.43664247, 0.46261925, 0.46646539,\n",
       "              0.41373339])                                               ,\n",
       "       array([0.55509703, 0.60672182, 0.43634852, 0.4627453 , 0.46807253,\n",
       "              0.41414337])                                               ,\n",
       "       ...,\n",
       "       array([0.52140983, 0.62151202, 0.40340263, 0.46222437, 0.4663783 ,\n",
       "              0.41403495])                                               ,\n",
       "       array([0.52133624, 0.62176777, 0.40339328, 0.46204742, 0.46645292,\n",
       "              0.41334122])                                               ,\n",
       "       array([0.52022656, 0.62188932, 0.40419165, 0.46230998, 0.46613546,\n",
       "              0.41295993])                                               ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_sensor_dat['measurements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a86f1f1-a6f2-4393-8c4c-d2a130ab9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
